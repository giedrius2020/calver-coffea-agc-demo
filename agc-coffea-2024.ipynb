{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688000d2-0ab3-4ff8-a4cc-f112422bac42",
   "metadata": {},
   "source": [
    "# AGC + calver coffea on coffea-casa\n",
    "\n",
    "We'll base this on a few sources:\n",
    "- https://github.com/iris-hep/analysis-grand-challenge/tree/main/analyses/cms-open-data-ttbar (AGC, of course)\n",
    "- https://github.com/alexander-held/CompHEP-2023-AGC (contains a simplified version of AGC)\n",
    "- https://github.com/nsmith-/TTGamma_LongExercise/ (credit Nick Smith for helpful examples of the new API)\n",
    "- (and if time allows, weight features: https://github.com/CoffeaTeam/coffea/blob/backports-v0.7.x/binder/accumulators.ipynb / https://coffeateam.github.io/coffea/api/coffea.analysis_tools.Weights.html#coffea.analysis_tools.Weights.partial_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:38.782002Z",
     "start_time": "2024-08-01T15:10:37.422997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.7\n",
      "dask-awkward: 2024.7.0\n",
      "dask: 2024.8.1\n",
      "uproot: 5.3.11.dev61+ga214027\n",
      "hist: 2.7.3\n",
      "coffea: 2024.8.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import awkward as ak\n",
    "import dask\n",
    "import dask_awkward as dak\n",
    "import hist.dask\n",
    "import coffea\n",
    "import numpy as np\n",
    "import uproot\n",
    "import traceback\n",
    "from dask.distributed import Client\n",
    "import skhep_testdata\n",
    "import pandas as pd\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "from coffea import dataset_tools\n",
    "\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "utils.plotting.set_style()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "NanoAODSchema.warn_missing_crossrefs = False # silences warnings about branches we will not use here\n",
    "\n",
    "\n",
    "client = Client(\"tls://localhost:8786\")\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"dask-awkward: {dak.__version__}\")\n",
    "print(f\"dask: {dask.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")\n",
    "print(f\"hist: {hist.__version__}\")\n",
    "print(f\"coffea: {coffea.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b8cc4-ee4a-4294-86d8-f5db8cf15aaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Produce an AGC histogram with Dask (no coffea yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e667cbdf-9e6f-4c7b-8827-2f6bb35c670b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:38.792459Z",
     "start_time": "2024-08-01T15:10:38.783403Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_trijet_mass(events):\n",
    "    # pT > 30 GeV for leptons, > 25 GeV for jets\n",
    "    selected_electrons = events.Electron[events.Electron.pt > 30 & (np.abs(events.Electron.eta) < 2.1)]\n",
    "    print(\"Selected electrons: \", selected_electrons)\n",
    "    selected_muons = events.Muon[events.Muon.pt > 30 & (np.abs(events.Muon.eta) < 2.1)]\n",
    "    selected_jets = events.Jet[events.Jet.pt > 25 & (np.abs(events.Jet.eta) < 2.4)]\n",
    "\n",
    "    # single lepton requirement\n",
    "    event_filters = ((ak.count(selected_electrons.pt, axis=1) + ak.count(selected_muons.pt, axis=1)) == 1)\n",
    "    # at least four jets\n",
    "    event_filters = event_filters & (ak.count(selected_jets.pt, axis=1) >= 4)\n",
    "    # at least two b-tagged jets (\"tag\" means score above threshold)\n",
    "    B_TAG_THRESHOLD = 0.5\n",
    "    event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2)\n",
    "\n",
    "    # apply filters\n",
    "    selected_jets = selected_jets[event_filters]\n",
    "\n",
    "    trijet = ak.combinations(selected_jets, 3, fields=[\"j1\", \"j2\", \"j3\"])  # trijet candidate\n",
    "    trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3  # four-momentum of tri-jet system\n",
    "\n",
    "    trijet[\"max_btag\"] = np.maximum(trijet.j1.btagCSVV2, np.maximum(trijet.j2.btagCSVV2, trijet.j3.btagCSVV2))\n",
    "    trijet = trijet[trijet.max_btag > B_TAG_THRESHOLD]  # at least one-btag in trijet candidates\n",
    "    # pick trijet candidate with largest pT and calculate mass of system\n",
    "    trijet_mass = trijet[\"p4\"][ak.argmax(trijet.p4.pt, axis=1, keepdims=True)].mass\n",
    "    return ak.flatten(trijet_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c972c",
   "metadata": {},
   "source": [
    "Reading in the ROOT file, we can now create a Dask task graph for the calculations and plot that we want to make using `dask-awkward` and `hist.dask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a00374a-83d5-48b8-8e68-7097936170ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:40.083914Z",
     "start_time": "2024-08-01T15:10:38.838844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was loaded with uproot, event count:  947\n",
      "File was loaded with uproot, event count:  947\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "events_list = []\n",
    "\n",
    "# Some files are downloaded locally:\n",
    "# all_files.append(ttbar_file)\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19981_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext4-v1_80000_0007.root\") # ttbar remote 533M size\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/rntuple/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # RNTuple remote\n",
    "all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # TTree remote\n",
    "all_files.append(\"/home/cms-jovyan/my_root_files/rntuple_v4.root\") # RNTuple, local, with our own converter v4 \n",
    "\n",
    "\n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/ttree/cmsopendata2015_ttbar_19981_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext4-v1_80000_0007.root\") # TTree ttbar original\n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/ttree/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # TTree local\n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/rntuple/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\")  # RNTuple local\n",
    "\n",
    "\n",
    "\n",
    "def load_files_with_uproot(files):\n",
    "    for fl in files:\n",
    "        with uproot.open(fl) as f:\n",
    "            events = f[\"Events\"]\n",
    "            events_list.append(events)\n",
    "            print(\"File was loaded with uproot, event count: \", len(events.keys()))\n",
    "            \n",
    "            # NOTE: to access array: # events.arrays([\"Electron_pt\"])[\"Electron_pt\"]\n",
    "        \n",
    "def load_files_with_coffea(files):\n",
    "    for fl in files:\n",
    "        events = NanoEventsFactory.from_root({fl: \"Events\"}, schemaclass=NanoAODSchema).events()\n",
    "        events_list.append(events)\n",
    "        print(\"File was loaded with coffea, fields count: \", len(events.fields))\n",
    "        \n",
    "        \n",
    "load_files_with_uproot(all_files)\n",
    "\n",
    "# load_files_with_coffea(all_files)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58212611-abcb-42ed-96fc-9ad0a0e61d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cell...\n",
      "TTree keys length: 947. RNTuple keys length: 947\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting cell...\")\n",
    "\n",
    "# file = all_files[1]\n",
    "\n",
    "events_tt = events_list[0]\n",
    "events_rn = events_list[1]\n",
    "\n",
    "\n",
    "\n",
    "# # Various available properties:\n",
    "# print(\"Name: \", events.name)\n",
    "# print(\"header: \", events.header)\n",
    "# print(\"footer: \", events.footer)\n",
    "# print(\"num_entries: \", events.num_entries)\n",
    "# print(\"len of field_names: \", len(events.field_names))\n",
    "# print(\"keys: \", len(events.keys()))\n",
    "\n",
    "# print(\" field_names: \", events.fields)\n",
    "\n",
    "\n",
    "# print(\"column_records: \", events.column_records[:10])\n",
    "# print(\"keys: \", events.keys()[:10])\n",
    "# print(\"_column_records_dict: \", events._column_records_dict)\n",
    "# print(\"_related_ids: \", events._related_ids)\n",
    "# print(\"page_list_envelopes: \", events.page_list_envelopes)\n",
    "\n",
    "\n",
    "# # Experimenting with array access:\n",
    "# array = events.arrays(filter_names=[\"Electron_pt\", \"Electron_eta\"])[:20]\n",
    "# print(\"events.arrays(): \", events.arrays())\n",
    "# print(\"----------\")\n",
    "# print(\"events.arrays().show(): \", events.arrays().show())\n",
    "# print(\"----------\")\n",
    "# # tree = uproot.open(file)\n",
    "\n",
    "\n",
    "\n",
    "# Must be sorted, because otherwise the order is different.\n",
    "keys_tt = sorted(events_tt.keys(), key=str.lower)\n",
    "keys_rn = sorted(events_rn._keys, key=str.lower)\n",
    "\n",
    "print(f\"TTree keys length: {len(keys_tt)}. RNTuple keys length: {len(keys_rn)}\")\n",
    "# print(\"\")\n",
    "\n",
    "def calculate_abs_difference(flat_ls1, flat_ls2):\n",
    "    # Calculate max(abs(x2-x1)):\n",
    "    # Ensure the arrays are of the same length\n",
    "    min_length = min(len(flat_ls1), len(flat_ls2))\n",
    "    \n",
    "    # Truncate arrays to the common length\n",
    "    flat_ls1_same_len = flat_ls1[:min_length]\n",
    "    flat_ls2_same_len = flat_ls2[:min_length]\n",
    "    \n",
    "    # Calculate the absolute differences\n",
    "    abs_differences = np.abs(np.array(flat_ls1_same_len) - np.array(flat_ls2_same_len))\n",
    "    \n",
    "    # Calculate the maximum absolute difference\n",
    "    max_abs_diff = np.max(abs_differences)\n",
    "    print(f\"Maximum absolute difference for key '{key}': {max_abs_diff}\")\n",
    "\n",
    "def draw_graph_flatten(key, arrays_tt, arrays_rn):\n",
    "    # Flatten the arrays\n",
    "    flat_tt = ak.ravel(arrays_tt).to_list()\n",
    "    flat_rn = ak.ravel(arrays_rn).to_list()\n",
    "    \n",
    "    \n",
    "    print(\"Len of rn after ravel:\", len(ak.ravel(arrays_rn)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # # Export mathcing sublists to a CSV file using pandas:\n",
    "    df = pd.DataFrame({\n",
    "        'flat_tt': pd.Series(flat_tt),\n",
    "        'flat_rn': pd.Series(flat_rn)\n",
    "        # 'tt': matching_sublists_tt,\n",
    "        # 'rn': matching_sublists_rn\n",
    "    })\n",
    "    df.to_csv(f'{key}_flattened.csv')\n",
    "    \n",
    "    # Create a range for the x-axis based on the length of the arrays\n",
    "    x_indices_tt = list(range(len(flat_tt)))\n",
    "    x_indices_rn = list(range(len(flat_rn)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot the scatter plot using the indices as x-values and array elements as y-values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x_indices_tt, flat_tt, color='blue', alpha=0.3, label='TTree (original files)')\n",
    "    plt.scatter(x_indices_rn, flat_rn, color='red', alpha=0.5, label='RNTuple (our converter)', marker=\"x\")\n",
    "    \n",
    "    # plt.yscale('log')\n",
    "    plt.ylim(0, 10)  # y-axis limits from 0 to 50\n",
    "\n",
    "    \n",
    "    # Labeling\n",
    "    plt.title(f\"Scatter Plot for Key: {key}\")\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Array Elements')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "def draw_graph_grouped(key, arrays_tt, arrays_rn):\n",
    "    # Flatten the arrays\n",
    "    # flat_tt = ak.ravel(arrays_tt).to_list()\n",
    "    # flat_rn = ak.ravel(arrays_rn).to_list()\n",
    "    \n",
    "    indices_of_matching_sublists = []\n",
    "    match_results = []\n",
    "    matching_sublists_tt = []\n",
    "    matching_sublists_rn = []\n",
    "\n",
    "    \n",
    "    for i, sublist_rn in enumerate(arrays_rn):\n",
    "        indices_of_matching_sublists.append(i)\n",
    "        try:\n",
    "            assert (len(arrays_tt[i]) == len(arrays_rn[i]) and all(arrays_tt[i] == arrays_rn[i]))\n",
    "            match_results.append(1)\n",
    "            matching_sublists_tt.append(arrays_tt[i])\n",
    "            matching_sublists_rn.append(arrays_rn[i])\n",
    "\n",
    "        except:\n",
    "            # print(f\"[{i}]\",arrays_tt[i], \"---\", arrays_rn[i])\n",
    "            match_results.append(0)\n",
    "            matching_sublists_tt.append(arrays_tt[i])\n",
    "            matching_sublists_rn.append(arrays_rn[i])\n",
    "\n",
    "#     print(\"TT indices len:\", len(x_indices_tt))\n",
    "#     print(\"RN indices len:\", len(x_indices_rn))\n",
    "    \n",
    "#     print(\"TT flat_tt len:\", len(flat_tt))\n",
    "#     print(\"RN flat_rn len:\", len(flat_rn))\n",
    "\n",
    "    \n",
    "    # Plot the scatter plot using the sublist indices as x-values and array elements as y-values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # plt.scatter(x_indices_tt, flat_tt, color='blue', alpha=0.3, label='TTree (original files)')\n",
    "    # plt.scatter(x_indices_rn, flat_rn, color='red', alpha=0.5, label='RNTuple (our converter)', marker=\"x\")\n",
    "    plt.scatter(indices_of_matching_sublists, match_results, s=2, color='green', alpha=0.2, label='RNTuple (our converter)')\n",
    "    \n",
    "    # # Export the values to a CSV file using pandas\n",
    "    # df = pd.DataFrame({\n",
    "    #     'Index': indices_of_matching_sublists,\n",
    "    #     'Match Result': match_results\n",
    "    # })\n",
    "    # df.to_csv(f'{key}_match_results.csv', index=False)\n",
    "    \n",
    "    # # # Export mathcing sublists to a CSV file using pandas:\n",
    "    # df = pd.DataFrame({\n",
    "    #     'Match Result': match_results,\n",
    "    #     'Index': indices_of_matching_sublists,\n",
    "    #     'tt': matching_sublists_tt,\n",
    "    #     'rn': matching_sublists_rn\n",
    "    # })\n",
    "    # df.to_csv(f'{key}_sublists.csv', index=False)\n",
    "\n",
    "    \n",
    "    # plt.xscale('log')\n",
    "    \n",
    "    # Labeling\n",
    "    plt.title(f\"Scatter Plot for Key: {key}\")\n",
    "    plt.xlabel('Sublist Index')\n",
    "    plt.ylabel('Does sublist match')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "def compare_key_lists(ls1, ls2):\n",
    "    match_count = 0\n",
    "    mismatch_count = 0\n",
    "    \n",
    "    ak_match_count = 0\n",
    "    ak_mismatch_count = 0\n",
    "    ak_error_count = 0\n",
    "    \n",
    "    count_of_all_tt_elements = 0\n",
    "    count_of_all_rn_elements = 0\n",
    "    \n",
    "    for i in range(len(ls1)):\n",
    "        if keys_tt[i] == keys_rn[i]:\n",
    "            key = keys_tt[i]\n",
    "            match_count+=1\n",
    "            # print(f\"\\r{i+1}/{len(ls1)}\", f\" {keys_tt[i]}\", end=\"\") # Progress indication without printing too many lines\n",
    "            # print(f\"{i+1}/{len(ls1)}\", f\" {keys_tt[i]}: \")\n",
    "            arrays_tt = events_tt.arrays([key])[key]\n",
    "            arrays_rn = events_rn.arrays([key])[key]\n",
    "            \n",
    "            el_count_tt = len(ak.ravel(arrays_tt))\n",
    "            el_count_rn = len(ak.ravel(arrays_rn))\n",
    "            \n",
    "            \n",
    "            \n",
    "            # print(f\"TT elements: {count_of_all_tt_elements}\")\n",
    "            # print(f\"RN elements: {count_of_all_rn_elements}\")\n",
    "\n",
    "            # Check if arrays are equal:\n",
    "            try:\n",
    "                are_equal = ak.all(arrays_tt == arrays_rn)\n",
    "                if are_equal:\n",
    "                    ak_match_count += 1\n",
    "                    print(f\"[{key}]\", \"ak arrays are equal\")\n",
    "                elif not are_equal:\n",
    "                    count_of_all_tt_elements+=el_count_tt\n",
    "                    count_of_all_rn_elements+=el_count_rn\n",
    "                    ak_mismatch_count += 1\n",
    "                    print(f\"[{key}]\", \"ak comparison MISMATCH\")\n",
    "                    print(\"tt: \", arrays_tt, f\"Type: {ak.type(arrays_tt)}. Count of elements: {el_count_tt}\")\n",
    "                    print(\"rn: \", arrays_rn, f\"Type: {ak.type(arrays_rn)}. Count of elements: {el_count_rn}\")\n",
    "                \n",
    "                # print(\"Arrays are equal: \", are_equal)  # Output: True\n",
    "            except:\n",
    "                count_of_all_tt_elements+=el_count_tt\n",
    "                count_of_all_rn_elements+=el_count_rn\n",
    "                ak_error_count += 1\n",
    "                print(f\"[{key}]\", \"ak comparison ERROR\")\n",
    "                print(\"tt: \", arrays_tt, f\"Type: {ak.type(arrays_tt)}. Count of elements: {el_count_tt}\")\n",
    "                print(\"rn: \", arrays_rn, f\"Type: {ak.type(arrays_rn)}. Count of elements: {el_count_rn}\")\n",
    "                # draw_graph_grouped(key, arrays_tt, arrays_rn)\n",
    "                draw_graph_flatten(key, arrays_tt, arrays_rn)\n",
    "                \n",
    "\n",
    "\n",
    "        else:\n",
    "            mismatch_count+=1\n",
    "            # print(\"Mismatch: \", keys_tt[i], \"---\", keys_rn[i])\n",
    "    print(f\"Keys comparison statistics: matched count: {match_count}; mismatch count: {mismatch_count}\")\n",
    "    print(f\"ak array comparison statistics: matched count: {ak_match_count}; mismatch count: {ak_mismatch_count}; errors: {ak_error_count}\")\n",
    "\n",
    "\n",
    "# compare_key_lists(keys_tt, keys_rn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for key in events: \n",
    "#     # branch = events.arrays([key])[key]\n",
    "#     print(key)\n",
    "\n",
    "\n",
    "## Things that do not work:\n",
    "# print(\"Show(): \", events.show()) # 'Model_ROOT_3a3a_Experimental_3a3a_RNTuple' object has no attribute 'show'\n",
    "# for key, branch in events.iteritems(): # Does not work with RNTuple. AttributeError: no field named 'iteritems'. However, it does work with TTree.\n",
    "# for key, branch in events.arrays().iteritems(): # Does not work both with TTree or RNTuple.\n",
    "# print(list(events.arrays().keys())) # Does not work. No field names keys()\n",
    "\n",
    "\n",
    "## Analyze why these keys mismatch. NOTE: It might be related to cardinality.\n",
    "# [HTXS_Higgs_y] ak comparison MISMATCH\n",
    "# [nCorrT1METJet] ak comparison MISMATCH\n",
    "# [nElectron] ak comparison MISMATCH\n",
    "# [nFatJet] ak comparison MISMATCH\n",
    "# [nFsrPhoton] ak comparison MISMATCH\n",
    "# [nGenDressedLepton] ak comparison MISMATCH\n",
    "# [nGenIsolatedPhoton] ak comparison MISMATCH\n",
    "# [nGenJet] ak comparison MISMATCH\n",
    "# [nGenJetAK8] ak comparison MISMATCH\n",
    "# [nGenPart] ak comparison MISMATCH\n",
    "# [nGenVisTau] ak comparison MISMATCH\n",
    "# [nJet] ak comparison MISMATCH\n",
    "# [nLHEPart] ak comparison MISMATCH\n",
    "# [nLHEPdfWeight] ak comparison MISMATCH\n",
    "# [nLHEScaleWeight] ak comparison MISMATCH\n",
    "# [nMuon] ak comparison MISMATCH\n",
    "# [nOtherPV] ak comparison MISMATCH\n",
    "# [nPhoton] ak comparison MISMATCH\n",
    "# [nPSWeight] ak comparison MISMATCH\n",
    "# [nSoftActivityJet] ak comparison MISMATCH\n",
    "# [nSV] ak comparison MISMATCH\n",
    "# [nTau] ak comparison MISMATCH\n",
    "# [SV_pAngle] ak comparison MISMATCH\n",
    "\n",
    "# Keys comparison statistics: matched count: 947; mismatch count: 0\n",
    "# ak array comparison statistics: matched count: 924; mismatch count: 23; errors: 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80c19e25-72c1-4d62-b15f-6ba332049573",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts of clusters:  [17224, 44433, 71709, 98997, 126243, 153500, 180739]\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [2, 5, 4, 3, 3, 2, 0, 0]\n",
      "RN array: [2, 5, 4, 3, 3, 2, 0, 18446744073709510780]\n",
      "Index:  17217 . Failure limits: (17217, 17225)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [5, 0, 4, 2, 3, 0, 2, 0]\n",
      "RN array: [5, 0, 4, 2, 3, 0, 2, 18446744073709487437]\n",
      "Index:  44426 . Failure limits: (44426, 44434)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [1, 1, 0, 3, 2, 5, 3, 0]\n",
      "RN array: [1, 1, 0, 3, 2, 5, 3, 18446744073709486641]\n",
      "Index:  71702 . Failure limits: (71702, 71710)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [3, 3, 1, 3, 2, 4, 2, 3]\n",
      "RN array: [3, 3, 1, 3, 2, 4, 2, 18446744073709486913]\n",
      "Index:  98990 . Failure limits: (98990, 98998)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [1, 5, 3, 1, 2, 3, 3, 1]\n",
      "RN array: [1, 5, 3, 1, 2, 3, 3, 18446744073709487456]\n",
      "Index:  126236 . Failure limits: (126236, 126244)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [5, 3, 6, 3, 3, 2, 1, 2]\n",
      "RN array: [5, 3, 6, 3, 3, 2, 1, 18446744073709487323]\n",
      "Index:  153493 . Failure limits: (153493, 153501)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT array: [1, 3, 1, 2, 1, 3, 6, 2]\n",
      "RN array: [1, 3, 1, 2, 1, 3, 6, 18446744073709486645]\n",
      "Index:  180732 . Failure limits: (180732, 180740)\n",
      "\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "Finished cell.\n"
     ]
    }
   ],
   "source": [
    "cluster_starts = [md.num_first_entry for md in events_rn.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "print(\"Starts of clusters: \", cluster_starts)\n",
    "print(\"\")\n",
    "key = \"nCorrT1METJet\"\n",
    "\n",
    "\n",
    "\n",
    "def collect_breaking_points(key):\n",
    "    step = 8\n",
    "    for cl_start in cluster_starts:\n",
    "        for i in range (cl_start-39, cl_start+39, step):\n",
    "            strt = i\n",
    "            end = i + step\n",
    "            arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "            arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "            \n",
    "            try:\n",
    "                assert (len(arr_tt) == len(arr_rn) and ak.all(arr_tt == arr_rn))\n",
    "                # print(\"EQUAL:\")\n",
    "                # print(f\"TT array: {ak.to_list(arr_tt)}\")\n",
    "                # print(f\"RN array: {ak.to_list(arr_rn)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"TT array: {arr_tt}\")\n",
    "                print(f\"RN array: {arr_rn}\")\n",
    "                print(\"Index: \", i, f\". Failure limits: {(strt, end)}\")\n",
    "                print(\"\")\n",
    "\n",
    "collect_breaking_points(key)\n",
    "\n",
    "print(\"Finished cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80cec75-8c1f-453d-a466-a9c6d546b8b2",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(events_tt.keys(filter_name=[\"run\", \"Electron_hoe\"]))\n",
    "# print(events_rn.keys(filter_name=[\"run\", \"Electron_hoe\"]))\n",
    "# print(events_rn.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3cb5c9e-e501-4e7b-8893-ad7fc0dc31df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts of clusters:  [17224, 44433, 71709, 98997, 126243, 153500, 180739]\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "TT: [3, 3, 2, 1, 2, 1, 3, 1, 1, 2]\n",
      "RN: [3, 3, 2, 1, 18446744073709487323, 2, 1, 3, 1, 1]\n",
      "Finished cell\n"
     ]
    }
   ],
   "source": [
    "print(\"Starts of clusters: \", cluster_starts)\n",
    "key = \"nCorrT1METJet\"\n",
    "\n",
    "strt = 153496\n",
    "end = strt + 10\n",
    "\n",
    "arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "\n",
    "print(\"TT:\", arr_tt)\n",
    "print(\"RN:\", arr_rn)\n",
    "\n",
    "print(\"Finished cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcdc37ec-220c-4716-92a5-d64aa6e47b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[uproot debug] key: column-4, dtype_byte: 17\n",
      "HTXS_Higgs_y TT: [nan, nan, nan, nan, nan, nan, nan, nan, ..., nan, nan, nan, nan, nan, nan, nan]  Len: 1000\n",
      "HTXS_Higgs_y RN: [nan, nan, nan, nan, nan, nan, nan, nan, ..., nan, nan, nan, nan, nan, nan, nan]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-581-cardinality, dtype_byte: 14\n",
      "nCorrT1METJet TT: [2, 2, 0, 0, 2, 2, 3, 5, 3, 2, 1, 4, 1, ..., 1, 1, 1, 5, 2, 2, 2, 1, 1, 0, 1, 3]  Len: 1000\n",
      "nCorrT1METJet RN: [2, 2, 0, 0, 2, 2, 3, 5, 3, 2, 1, 4, 1, ..., 3, 1, 1, 1, 5, 2, 2, 2, 1, 1, 0, 1]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-587-cardinality, dtype_byte: 14\n",
      "nElectron TT: [2, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 3, 0, ..., 1, 3, 2, 2, 4, 1, 2, 1, 3, 3, 2, 1]  Len: 1000\n",
      "nElectron RN: [2, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 3, 0, ..., 0, 1, 3, 2, 2, 4, 1, 2, 1, 3, 3, 2]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-641-cardinality, dtype_byte: 14\n",
      "nFatJet TT: [1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 1, ..., 1, 1, 2, 1, 1, 2, 0, 0, 2, 2, 0, 1]  Len: 1000\n",
      "nFatJet RN: [1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 1, ..., 0, 1, 1, 2, 1, 1, 2, 0, 0, 2, 2, 0]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-694-cardinality, dtype_byte: 14\n",
      "nFsrPhoton TT: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  Len: 1000\n",
      "nFsrPhoton RN: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-701-cardinality, dtype_byte: 14\n",
      "nGenDressedLepton TT: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, ..., 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]  Len: 1000\n",
      "nGenDressedLepton RN: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, ..., 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-708-cardinality, dtype_byte: 14\n",
      "nGenIsolatedPhoton TT: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  Len: 1000\n",
      "nGenIsolatedPhoton RN: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-713-cardinality, dtype_byte: 14\n",
      "nGenJet TT: [10, 10, 3, 6, 8, 9, 8, 17, 9, 5, 5, ..., 8, 10, 8, 12, 12, 8, 7, 12, 8, 7, 8]  Len: 1000\n",
      "nGenJet RN: [10, 10, 3, 6, 8, 9, 8, 17, 9, 5, 5, ..., 7, 8, 10, 8, 12, 12, 8, 7, 12, 8, 7]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-720-cardinality, dtype_byte: 14\n",
      "nGenJetAK8 TT: [1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 2, ..., 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 0, 1]  Len: 1000\n",
      "nGenJetAK8 RN: [1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 2, ..., 0, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 0]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-727-cardinality, dtype_byte: 14\n",
      "nGenPart TT: [46, 47, 35, 33, 48, 40, 55, 66, 56, ..., 49, 79, 79, 53, 44, 61, 49, 71, 60]  Len: 1000\n",
      "nGenPart RN: [46, 47, 35, 33, 48, 40, 55, 66, 56, ..., 73, 49, 79, 79, 53, 44, 61, 49, 71]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-736-cardinality, dtype_byte: 14\n",
      "nGenVisTau TT: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]  Len: 1000\n",
      "nGenVisTau RN: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-744-cardinality, dtype_byte: 14\n",
      "nJet TT: [9, 11, 3, 6, 7, 8, 6, 14, 13, 5, 6, 9, ..., 9, 9, 7, 14, 11, 8, 8, 11, 9, 8, 6]  Len: 1000\n",
      "nJet RN: [9, 11, 3, 6, 7, 8, 6, 14, 13, 5, 6, 9, ..., 7, 9, 9, 7, 14, 11, 8, 8, 11, 9, 8]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-785-cardinality, dtype_byte: 14\n",
      "nLHEPart TT: [8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, ..., 8, 8, 9, 8, 9, 9, 8, 8, 8, 9, 9, 9]  Len: 1000\n",
      "nLHEPart RN: [8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, ..., 9, 8, 8, 9, 8, 9, 9, 8, 8, 8, 9, 9]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-794-cardinality, dtype_byte: 14\n",
      "nLHEPdfWeight TT: [102, 102, 102, 102, 102, 102, 102, 102, ..., 102, 102, 102, 102, 102, 102, 102]  Len: 1000\n",
      "nLHEPdfWeight RN: [102, 102, 102, 102, 102, 102, 102, 102, ..., 102, 102, 102, 102, 102, 102, 102]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-798-cardinality, dtype_byte: 14\n",
      "nLHEScaleWeight TT: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ..., 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]  Len: 1000\n",
      "nLHEScaleWeight RN: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ..., 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-800-cardinality, dtype_byte: 14\n",
      "nMuon TT: [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, ..., 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]  Len: 1000\n",
      "nMuon RN: [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, ..., 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-858-cardinality, dtype_byte: 14\n",
      "nOtherPV TT: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ..., 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  Len: 1000\n",
      "nOtherPV RN: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ..., 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-862-cardinality, dtype_byte: 14\n",
      "nPhoton TT: [2, 1, 1, 2, 1, 1, 1, 3, 1, 0, 2, 2, 1, ..., 2, 1, 0, 4, 2, 2, 3, 2, 2, 4, 3, 2]  Len: 1000\n",
      "nPhoton RN: [2, 1, 1, 2, 1, 1, 1, 3, 1, 0, 2, 2, 1, ..., 2, 2, 1, 0, 4, 2, 2, 3, 2, 2, 4, 3]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-860-cardinality, dtype_byte: 14\n",
      "nPSWeight TT: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ..., 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  Len: 1000\n",
      "nPSWeight RN: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ..., 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-909-cardinality, dtype_byte: 14\n",
      "nSoftActivityJet TT: [6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, ..., 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  Len: 1000\n",
      "nSoftActivityJet RN: [6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, ..., 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-892-cardinality, dtype_byte: 14\n",
      "nSV TT: [5, 2, 2, 0, 3, 0, 2, 1, 2, 3, 2, 2, 2, ..., 3, 2, 1, 2, 4, 5, 2, 3, 2, 2, 0, 2]  Len: 1000\n",
      "nSV RN: [5, 2, 2, 0, 3, 0, 2, 1, 2, 3, 2, 2, 2, ..., 3, 3, 2, 1, 2, 4, 5, 2, 3, 2, 2, 0]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n",
      "[uproot debug] key: column-913-cardinality, dtype_byte: 14\n",
      "nTau TT: [0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, ..., 1, 2, 0, 2, 0, 0, 3, 0, 1, 1, 1, 0]  Len: 1000\n",
      "nTau RN: [0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, ..., 0, 1, 2, 0, 2, 0, 0, 3, 0, 1, 1, 1]  Len: 1000\n",
      "____________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keys with mismatching arrays between TT and RN:\n",
    "keys = [\"HTXS_Higgs_y\",\n",
    "\"nCorrT1METJet\",\n",
    "\"nElectron\",\n",
    "\"nFatJet\",\n",
    "\"nFsrPhoton\",\n",
    "\"nGenDressedLepton\",\n",
    "\"nGenIsolatedPhoton\",\n",
    "\"nGenJet\",\n",
    "\"nGenJetAK8\",\n",
    "\"nGenPart\",\n",
    "\"nGenVisTau\",\n",
    "\"nJet\",\n",
    "\"nLHEPart\",\n",
    "\"nLHEPdfWeight\",\n",
    "\"nLHEScaleWeight\",\n",
    "\"nMuon\",\n",
    "\"nOtherPV\",\n",
    "\"nPhoton\",\n",
    "\"nPSWeight\",\n",
    "\"nSoftActivityJet\",\n",
    "\"nSV\",\n",
    "\"nTau\",\n",
    "\"SV_pAngle\"]\n",
    "# for key in keys:\n",
    "#     arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "#     arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "\n",
    "#     print(f\"{key} TT:\", arr_tt, f\" Len: {len(arr_tt)}\")\n",
    "#     print(f\"{key} RN:\", arr_rn, f\" Len: {len(arr_rn)}\")\n",
    "#     print(f\"____________________________________________________________________________________________________________________\")\n",
    "# for key in events_rn.keys(): # all keys\n",
    "#     # arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "#     arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "#     print(f\"____________________________________________________________________________________________________________________\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Finished cell\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f0b5d9-cd7a-4f86-bca3-a2e8a15f9570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:40.088275Z",
     "start_time": "2024-08-01T15:10:40.085122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Test times for each function:\n",
    "\n",
    "# import timeit\n",
    "\n",
    "# # Define the operations as functions\n",
    "# def array_1():\n",
    "#     print(events_list[0].arrays([\"Electron_pt\"])[\"Electron_pt\"])\n",
    "\n",
    "# def array_1_direct():\n",
    "#     print(events_list[0][\"Electron_pt\"].array())\n",
    "\n",
    "# def array_2():\n",
    "#     print(events_list[1].arrays([\"Electron_pt\"])[\"Electron_pt\"])\n",
    "\n",
    "# def array_2_direct():\n",
    "#     print(events_list[1][\"Electron_pt\"].array())\n",
    "\n",
    "# def array_3():\n",
    "#     print(events_list[2].arrays([\"Electron_pt\"])[\"Electron_pt\"])\n",
    "\n",
    "# def array_3_direct():\n",
    "#     print(events_list[2][\"Electron_pt\"].array())\n",
    "\n",
    "# # Time the operations\n",
    "# time_1 = timeit.timeit(array_1, number=1)\n",
    "# print(\"Time for events1.arrays(['Electron_pt'])['Electron_pt']: \", time_1)\n",
    "# time_1_direct = timeit.timeit(array_1_direct, number=1)\n",
    "# print(\"Time for events1['Electron_pt'].array(): \", time_1_direct)\n",
    "\n",
    "# print(\"*****\")\n",
    "\n",
    "# time_2 = timeit.timeit(array_2, number=1)\n",
    "# print(\"Time for events2.arrays(['Electron_pt'])['Electron_pt']: \", time_2)\n",
    "# time_2_direct = timeit.timeit(array_2_direct, number=1)\n",
    "# print(\"Time for events2['Electron_pt'].array(): \", time_2_direct)\n",
    "\n",
    "# print(\"*****\")\n",
    "\n",
    "# time_3 = timeit.timeit(array_3, number=1)\n",
    "# print(\"Time for events3.arrays(['Electron_pt'])['Electron_pt']: \", time_3)\n",
    "# time_3_direct = timeit.timeit(array_3_direct, number=1)\n",
    "# print(\"Time for events3['Electron_pt'].array(): \", time_3_direct)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c15f7ba-1f90-41b3-8f44-8e6f59b9974c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:40.203342Z",
     "start_time": "2024-08-01T15:10:40.106928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating trijet mass...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model_TTree_v20' object has no attribute 'Electron'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create the task graph to build a histogram\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating trijet mass...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m reconstructed_top_mass \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_trijet_mass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist_reco_mtop...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m hist_reco_mtop \u001b[38;5;241m=\u001b[39m hist\u001b[38;5;241m.\u001b[39mdask\u001b[38;5;241m.\u001b[39mHist\u001b[38;5;241m.\u001b[39mnew\u001b[38;5;241m.\u001b[39mReg(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m375\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$m_\u001b[39m\u001b[38;5;132;01m{bjj}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mDouble()\u001b[38;5;241m.\u001b[39mfill(reconstructed_top_mass)\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36mcalculate_trijet_mass\u001b[0;34m(events)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_trijet_mass\u001b[39m(events):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# pT > 30 GeV for leptons, > 25 GeV for jets\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     selected_electrons \u001b[38;5;241m=\u001b[39m \u001b[43mevents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mElectron\u001b[49m[events\u001b[38;5;241m.\u001b[39mElectron\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mabs(events\u001b[38;5;241m.\u001b[39mElectron\u001b[38;5;241m.\u001b[39meta) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2.1\u001b[39m)]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected electrons: \u001b[39m\u001b[38;5;124m\"\u001b[39m, selected_electrons)\n\u001b[1;32m      5\u001b[0m     selected_muons \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mMuon[events\u001b[38;5;241m.\u001b[39mMuon\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m&\u001b[39m (np\u001b[38;5;241m.\u001b[39mabs(events\u001b[38;5;241m.\u001b[39mMuon\u001b[38;5;241m.\u001b[39meta) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2.1\u001b[39m)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model_TTree_v20' object has no attribute 'Electron'"
     ]
    }
   ],
   "source": [
    "# create the task graph to build a histogram\n",
    "print(\"Calculating trijet mass...\")\n",
    "reconstructed_top_mass = calculate_trijet_mass(events_list[0])\n",
    "print(\"hist_reco_mtop...\")\n",
    "hist_reco_mtop = hist.dask.Hist.new.Reg(16, 0, 375, label=\"$m_{bjj}$\").Double().fill(reconstructed_top_mass)\n",
    "print(\"Finished cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad62a29",
   "metadata": {},
   "source": [
    "and then once we're ready we can execute the task graph with `.compute()` to get our visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3d2d1-7b45-47f6-830d-7c46b479f7d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:21:58.923162Z",
     "start_time": "2024-08-01T15:10:40.204505Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform computation and visualize\n",
    "artists = hist_reco_mtop.compute().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998956ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and annotate the visualization\n",
    "fig_dir = Path.cwd() / \"figures\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ax = artists[0].stairs.axes\n",
    "fig = ax.get_figure()\n",
    "ax.vlines(175, 0, 10000, colors=[\"grey\"], linestyle=\"dotted\")\n",
    "ax.text(180, 150, \"$m_{t} = 175$ GeV\")\n",
    "ax.set_xlim([0, 375])\n",
    "ax.set_ylim([0, 8000])\n",
    "\n",
    "fig.savefig(fig_dir / \"trijet_mass.png\", dpi=300)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2d6bd-b316-4627-a90c-a8c7e4a028e9",
   "metadata": {},
   "source": [
    "This all matches the (non-Dask) versions of the plots from last summer â€” see the notebook linked above. Not surprising, but reassuring!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb5a13-a8c0-4236-9c71-7ec6847773cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time for coffea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6684c8",
   "metadata": {},
   "source": [
    "We'll first write the functions to compute the observable and do the histogramming using `awkward-dask` and `hist.dask` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38efe4-8024-422c-ba42-12bd3a3b44cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_TAG_THRESHOLD = 0.5\n",
    "\n",
    "# perform object selection\n",
    "def object_selection(events):\n",
    "    elecs = events.Electron\n",
    "    muons = events.Muon\n",
    "    jets = events.Jet\n",
    "\n",
    "    electron_reqs = (elecs.pt > 30) & (np.abs(elecs.eta) < 2.1) & (elecs.cutBased == 4) & (elecs.sip3d < 4)\n",
    "    muon_reqs = ((muons.pt > 30) & (np.abs(muons.eta) < 2.1) & (muons.tightId) & (muons.sip3d < 4) &\n",
    "                 (muons.pfRelIso04_all < 0.15))\n",
    "    jet_reqs = (jets.pt > 30) & (np.abs(jets.eta) < 2.4) & (jets.isTightLeptonVeto)\n",
    "\n",
    "    # Only keep objects that pass our requirements\n",
    "    elecs = elecs[electron_reqs]\n",
    "    muons = muons[muon_reqs]\n",
    "    jets = jets[jet_reqs]\n",
    "\n",
    "    return elecs, muons, jets\n",
    "\n",
    "\n",
    "# event selection for 4j1b and 4j2b\n",
    "def region_selection(elecs, muons, jets):\n",
    "    ######### Store boolean masks with PackedSelection ##########\n",
    "    selections = PackedSelection(dtype='uint64')\n",
    "    # Basic selection criteria\n",
    "    selections.add(\"exactly_1l\", (ak.num(elecs) + ak.num(muons)) == 1)\n",
    "    selections.add(\"atleast_4j\", ak.num(jets) >= 4)\n",
    "    selections.add(\"exactly_1b\", ak.sum(jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) == 1)\n",
    "    selections.add(\"atleast_2b\", ak.sum(jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2)\n",
    "    # Complex selection criteria\n",
    "    selections.add(\"4j1b\", selections.all(\"exactly_1l\", \"atleast_4j\", \"exactly_1b\"))\n",
    "    selections.add(\"4j2b\", selections.all(\"exactly_1l\", \"atleast_4j\", \"atleast_2b\"))\n",
    "\n",
    "    return selections.all(\"4j1b\"), selections.all(\"4j2b\")\n",
    "\n",
    "\n",
    "# observable calculation for 4j2b\n",
    "def calculate_m_reco_top(jets):\n",
    "    # reconstruct hadronic top as bjj system with largest pT\n",
    "    trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])  # trijet candidates\n",
    "    trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3  # four-momentum of tri-jet system\n",
    "    trijet[\"max_btag\"] = np.maximum(trijet.j1.btagCSVV2,\n",
    "                                    np.maximum(trijet.j2.btagCSVV2, trijet.j3.btagCSVV2))\n",
    "    trijet = trijet[trijet.max_btag > B_TAG_THRESHOLD]  # at least one-btag in candidates\n",
    "    # pick trijet candidate with largest pT and calculate mass of system\n",
    "    trijet_mass = trijet[\"p4\"][ak.argmax(trijet.p4.pt, axis=1, keepdims=True)].mass\n",
    "    observable = ak.flatten(trijet_mass)\n",
    "\n",
    "    return observable\n",
    "\n",
    "\n",
    "# create histograms with observables\n",
    "def create_histograms(events):\n",
    "    hist_4j1b = (\n",
    "        hist.dask.Hist.new.Reg(25, 50, 550, name=\"HT\", label=r\"$H_T$ [GeV]\")\n",
    "        .StrCat([], name=\"process\", label=\"Process\", growth=True)\n",
    "        .StrCat([], name=\"variation\", label=\"Systematic variation\", growth=True)\n",
    "        .Weight()\n",
    "    )\n",
    "\n",
    "    hist_4j2b = (\n",
    "        hist.dask.Hist.new.Reg(25, 50, 550, name=\"m_reco_top\", label=r\"$m_{bjj}$ [GeV]\")\n",
    "        .StrCat([], name=\"process\", label=\"Process\", growth=True)\n",
    "        .StrCat([], name=\"variation\", label=\"Systematic variation\", growth=True)\n",
    "        .Weight()\n",
    "    )\n",
    "\n",
    "    process = events.metadata[\"process\"]  # \"ttbar\" etc.\n",
    "    variation = events.metadata[\"variation\"]  # \"nominal\" etc.\n",
    "    process_label = events.metadata[\"process_label\"]  # nicer LaTeX labels\n",
    "\n",
    "    # normalization for MC\n",
    "    x_sec = events.metadata[\"xsec\"]\n",
    "    nevts_total = events.metadata[\"nevts\"]\n",
    "    lumi = 3378 # /pb\n",
    "    if process != \"data\":\n",
    "        xsec_weight = x_sec * lumi / nevts_total\n",
    "    else:\n",
    "        xsec_weight = 1\n",
    "\n",
    "    elecs, muons, jets = object_selection(events)\n",
    "\n",
    "    # region selection\n",
    "    selection_4j1b, selection_4j2b = region_selection(elecs, muons, jets)\n",
    "\n",
    "    # 4j1b: HT\n",
    "    observable_4j1b = ak.sum(jets[selection_4j1b].pt, axis=-1)\n",
    "    hist_4j1b.fill(observable_4j1b, weight=xsec_weight, process=process_label, variation=variation)\n",
    "\n",
    "    # 4j2b: m_reco_top\n",
    "    observable_4j2b = calculate_m_reco_top(jets[selection_4j2b])\n",
    "    hist_4j2b.fill(observable_4j2b, weight=xsec_weight, process=process_label, variation=variation)\n",
    "\n",
    "    return {\"4j1b\": hist_4j1b, \"4j2b\": hist_4j2b}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3816c2",
   "metadata": {},
   "source": [
    "and prepare the fileset we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b151e-d7a8-49d4-8368-310cbe149b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileset preparation\n",
    "N_FILES_MAX_PER_SAMPLE = 1\n",
    "# compared to coffea 0.7: list of file paths becomes list of dicts (path: trename)\n",
    "fileset = utils.file_input.construct_fileset(N_FILES_MAX_PER_SAMPLE)\n",
    "\n",
    "# fileset = {\"ttbar__nominal\": fileset[\"ttbar__nominal\"]}  # to only process nominal ttbar\n",
    "# fileset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed65cdb",
   "metadata": {},
   "source": [
    "Now we can start using `coffea` with its Dask capabilities. One of the things we need to do is to build the full task graph, which requires looping over all the sample variations (`samples`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ecc41-0a72-44ec-a8b8-654286a02196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# pre-process\n",
    "samples, _ = dataset_tools.preprocess(fileset, step_size=250_000)\n",
    "\n",
    "# workaround for https://github.com/CoffeaTeam/coffea/issues/1050 (metadata gets dropped, already fixed)\n",
    "for k, v in samples.items():\n",
    "    v[\"metadata\"] = fileset[k][\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15835a57-1182-4efb-8306-07f36af7a5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create the task graph\n",
    "tasks = dataset_tools.apply_to_fileset(create_histograms, samples, uproot_options={\"allow_read_errors_with_report\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953d6d",
   "metadata": {},
   "source": [
    "and then we can finally execute the full task graph with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dfb17-6806-46c8-aa59-cd475e40cf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# execute\n",
    "((out, report),) = dask.compute(tasks)  # feels strange that this is a tuple-of-tuple\n",
    "\n",
    "print(f\"total time spent in uproot reading data (or some related metric?): {ak.sum([v['duration'] for v in report.values()]):.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c7fad",
   "metadata": {},
   "source": [
    "To visualize the results, we need to first stack the serperate histograms that were computed individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714929f5-9c56-4afa-87e6-5d096af21ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stack all the histograms together (we processed each sample separately)\n",
    "full_histogram_4j1b = sum([v[\"4j1b\"] for v in out.values()])\n",
    "full_histogram_4j2b = sum([v[\"4j2b\"] for v in out.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c0147-6b4e-4ae7-b4e1-b8eb6b764c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artists = full_histogram_4j1b[120j::hist.rebin(2), :, \"nominal\"].stack(\"process\")[::-1].plot(\n",
    "    stack=True, histtype=\"fill\", linewidth=1,edgecolor=\"grey\"\n",
    ")\n",
    "\n",
    "ax = artists[0].stairs.axes\n",
    "fig = ax.get_figure()\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\">= 4 jets, 1 b-tag\");\n",
    "\n",
    "fig.savefig(fig_dir / \"coffea_4j_1b.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba9e07-ec3c-4cdb-be16-4cab17e02a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artists = full_histogram_4j2b[:, :, \"nominal\"].stack(\"process\")[::-1].plot(\n",
    "    stack=True, histtype=\"fill\", linewidth=1,edgecolor=\"grey\"\n",
    ")\n",
    "\n",
    "ax = artists[0].stairs.axes\n",
    "fig = ax.get_figure()\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\">= 4 jets, >= 2 b-tags\");\n",
    "\n",
    "fig.savefig(fig_dir / \"coffea_4j_2b.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa67e0-be77-4f70-8a2d-02446ef7793c",
   "metadata": {},
   "source": [
    "This is a plot you can compare to the one in the full AGC notebook â€” you'll notice they look the same. Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a83e2",
   "metadata": {},
   "source": [
    "If we now investigate the task graph for the nominal $t\\bar{t}$ sample in the optimzied view, which hides from us some of the complexity of the graph we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9195b47-34d0-4947-9691-1563580c3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks[0][\"ttbar__nominal\"][\"4j2b\"].visualize(optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fca3c-6e3e-42f8-a917-c843822b1f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"100 layers is a large task graph\" on IRIS-HEP Slack, 100 layers happen quickly!\n",
    "for region in [\"4j1b\", \"4j2b\"]:\n",
    "    for process, task in tasks[0].items():\n",
    "        print(f\"{process:>30} {region} {len(task[region].dask.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04c78a-926f-47fb-956c-ef2355213514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# columns getting read for a given task\n",
    "dak.necessary_columns(tasks[0][\"ttbar__nominal\"][\"4j2b\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
