{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4baf183-a742-40e4-975a-03423411693e",
   "metadata": {},
   "source": [
    "### TTree and RNTuple loading comparison while using uproot\n",
    "\n",
    "Sources:\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:38.782002Z",
     "start_time": "2024-08-01T15:10:37.422997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.7\n",
      "uproot: 5.3.13.dev17+g5bf176d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a00374a-83d5-48b8-8e68-7097936170ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:40.083914Z",
     "start_time": "2024-08-01T15:10:38.838844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = {}\n",
    "events_list = []\n",
    "\n",
    "# Some files are downloaded locally:\n",
    "# all_files.append(ttbar_file)\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19981_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext4-v1_80000_0007.root\") # ttbar remote 533M size\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/rntuple/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # RNTuple remote\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # TTree remote\n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/rntuple_v1.root\") # RNTuple, local, with our own converter v4 \n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/rntuple_v2.root\") # RNTuple, local, with our own converter v4 \n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/rntuple_v3.root\") # RNTuple, local, with our own converter v4 \n",
    "\n",
    "# all_files.append(\"/home/cms-jovyan/my_root_files/rntuple_v4.root\") # RNTuple, local, with our own converter v4 \n",
    "\n",
    "# Files downloaded locally:\n",
    "# all_files[\"TT\"] = \"/home/cms-jovyan/my_root_files/ttree/cmsopendata2015_ttbar_19981_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext4-v1_80000_0007.root\") # TTree ttbar original\n",
    "all_files[\"TT\"] = \"/home/cms-jovyan/my_root_files/ttree/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\" # TTree local\n",
    "all_files[\"RN\"] = \"/home/cms-jovyan/my_root_files/rntuple/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\"  # RNTuple local\n",
    "\n",
    "# all_files[\"632\"] = \"/home/cms-jovyan/my_root_files/rntuple_v6_632_0909.root\" # RNTuple, ROOT_632 (works)\n",
    "# all_files[\"6x\"] = \"/home/cms-jovyan/my_root_files/rntuple_v7_6_0909.root\" # RNTuple, ROOT_6_X (does not work)\n",
    "\n",
    "\n",
    "def load_files_with_uproot(files):\n",
    "    for fl in files.values():\n",
    "        with uproot.open(fl) as f:\n",
    "            events = f[\"Events\"]\n",
    "            events_list.append(events)\n",
    "            # print(\"File was loaded with uproot, event count: \", len(events.keys()))\n",
    "            \n",
    "            # NOTE: to access array: # events.arrays([\"Electron_pt\"])[\"Electron_pt\"]\n",
    "        \n",
    "def load_files_with_coffea(files):\n",
    "    for fl in files:\n",
    "        events = NanoEventsFactory.from_root({fl: \"Events\"}, schemaclass=NanoAODSchema).events()\n",
    "        events_list.append(events)\n",
    "        print(\"File was loaded with coffea, fields count: \", len(events.fields))\n",
    "        \n",
    "load_files_with_uproot(all_files)\n",
    "\n",
    "# load_files_with_coffea(all_files)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1800f9-82ab-44c2-9344-62a7ff6e617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Various available properties:\n",
    "# print(\"Name: \", events.name)\n",
    "# print(\"header: \", events.header)\n",
    "# print(\"footer: \", events.footer)\n",
    "# print(\"num_entries: \", events.num_entries)\n",
    "# print(\"len of field_names: \", len(events.field_names))\n",
    "# print(\"keys: \", len(events.keys()))\n",
    "# print(\" field_names: \", events.fields)\n",
    "# print(\"column_records: \", events.column_records[:10])\n",
    "# print(\"keys: \", events.keys()[:10])\n",
    "# print(\"_column_records_dict: \", events._column_records_dict)\n",
    "# print(\"_related_ids: \", events._related_ids)\n",
    "# print(\"page_list_envelopes: \", events.page_list_envelopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959fd9d-0c77-4cc5-b493-63eb613c2833",
   "metadata": {},
   "source": [
    "### timeit tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ee5919-2dcb-49f9-8065-2967a192620a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "events_dict = {}\n",
    "\n",
    "def format_test_results(times):\n",
    "    df = pd.DataFrame(times, columns =['data_type', 'func_name', 'time(s)'])\n",
    "    df = df.sort_values(by=['func_name'])\n",
    "    df['time(s)'] = df['time(s)'].round(4)\n",
    "    df['func_name'] = df['func_name'].str.replace('_', ' ', regex=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_file(data_type, file):\n",
    "    with uproot.open(file) as f:\n",
    "        events = f[\"Events\"]\n",
    "        events_dict[data_type] = events\n",
    "\n",
    "def load_arrays_for_each_key(events):\n",
    "    for key in events.keys():\n",
    "        events.arrays(filter_name=[key])[key]\n",
    "        \n",
    "def load_all_arrays(events):\n",
    "    events.arrays()\n",
    "    \n",
    "def load_all_arrays_while_using_filter_name(events):\n",
    "    chosen_keys = events.keys()\n",
    "    events.arrays(filter_name=chosen_keys)[chosen_keys]\n",
    "\n",
    "def load_array_while_using_filter_name(events):\n",
    "    key = \"nGenVisTau\"\n",
    "    events.arrays(filter_name=[key])[key]\n",
    "    \n",
    "    \n",
    "def load_10_arrays_while_using_filter_name(events):\n",
    "    chosen_keys = [ \"nGenVisTau\",\n",
    "                    \"GenVisTau_eta\",\n",
    "                    \"GenVisTau_mass\",\n",
    "                    \"GenVisTau_phi\",\n",
    "                    \"GenVisTau_pt\",\n",
    "                    \"GenVisTau_charge\",\n",
    "                    \"GenVisTau_genPartIdxMother\",\n",
    "                    \"GenVisTau_status\",\n",
    "                    \"genWeight\",\n",
    "                    \"LHEWeight_originalXWGTUP\"]\n",
    "    \n",
    "    events.arrays(filter_name=chosen_keys)[chosen_keys]\n",
    "        \n",
    "def start_all_performance_tests():\n",
    "    print(\"Starting to timeit on various functions: \")\n",
    "    times = []\n",
    "    \n",
    "    for data_type, file in all_files.items():\n",
    "        time_taken = timeit.timeit(lambda: load_file(data_type, file), number=1)\n",
    "        times.append((data_type, \"load_file\", time_taken))\n",
    "\n",
    "        time_taken = timeit.timeit(lambda: load_arrays_for_each_key(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_arrays_for_each_key\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_all_arrays(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_all_arrays\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_all_arrays_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_all_arrays_while_using_filter_name\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_10_arrays_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_10_arrays_while_using_filter_name\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_array_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_array_while_using_filter_name\", time_taken))\n",
    "\n",
    "    \n",
    "    return format_test_results(times)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58212611-abcb-42ed-96fc-9ad0a0e61d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell compares keys for TTree and RNTuple. For each matching key, it compares all array values. At the end, comparison statistics are printed.\n",
    "def compare_key_lists(ls1, ls2):\n",
    "    match_count = 0\n",
    "    mismatch_count = 0\n",
    "    \n",
    "    ak_match_count = 0\n",
    "    ak_mismatch_count = 0\n",
    "    ak_error_count = 0\n",
    "    \n",
    "    count_of_all_tt_elements = 0\n",
    "    count_of_all_rn_elements = 0\n",
    "    \n",
    "    for i in range(len(ls1)):\n",
    "        if keys_tt[i] == keys_rn[i]:\n",
    "            key = keys_tt[i]\n",
    "            match_count+=1\n",
    "\n",
    "            arrays_tt = events_tt.arrays([key])[key]\n",
    "            arrays_rn = events_rn.arrays([key])[key]\n",
    "            \n",
    "            el_count_tt = len(ak.ravel(arrays_tt))\n",
    "            el_count_rn = len(ak.ravel(arrays_rn))\n",
    "            \n",
    "\n",
    "            # Check if arrays are equal:\n",
    "            try:                \n",
    "                # Custom function to compare NaN-aware equality\n",
    "                def nan_equal(x, y):\n",
    "                    if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                        return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "                    return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "                # Check if the lengths of the outermost arrays are equal\n",
    "                assert len(arrays_tt) == len(arrays_rn)\n",
    "                \n",
    "                # Compare the arrays using the custom function\n",
    "                are_equal = nan_equal(arrays_tt.tolist(), arrays_rn.tolist())\n",
    "                \n",
    "                if are_equal:\n",
    "                    ak_match_count += 1\n",
    "                    print(f\"[{key}]\", \"ak arrays are equal\")\n",
    "                elif not are_equal:\n",
    "                    count_of_all_tt_elements+=el_count_tt\n",
    "                    count_of_all_rn_elements+=el_count_rn\n",
    "                    ak_mismatch_count += 1\n",
    "                    print(f\"[{key}]\", \"ak comparison MISMATCH\")\n",
    "                    print(\"tt: \", arrays_tt, f\"Type: {ak.type(arrays_tt)}. Count of elements: {el_count_tt}\")\n",
    "                    print(\"rn: \", arrays_rn, f\"Type: {ak.type(arrays_rn)}. Count of elements: {el_count_rn}\")\n",
    "                \n",
    "            except:\n",
    "                count_of_all_tt_elements+=el_count_tt\n",
    "                count_of_all_rn_elements+=el_count_rn\n",
    "                ak_error_count += 1\n",
    "                print(f\"[{key}]\", \"ak comparison ERROR\")\n",
    "                print(\"tt: \", arrays_tt, f\"Type: {ak.type(arrays_tt)}. Count of elements: {el_count_tt}\")\n",
    "                print(\"rn: \", arrays_rn, f\"Type: {ak.type(arrays_rn)}. Count of elements: {el_count_rn}\")\n",
    "        else:\n",
    "            mismatch_count+=1\n",
    "            # print(\"Mismatch: \", keys_tt[i], \"---\", keys_rn[i])\n",
    "    print(f\"Keys comparison statistics: matched count: {match_count}; mismatch count: {mismatch_count}\")\n",
    "    print(f\"ak array comparison statistics: matched count: {ak_match_count}; mismatch count: {ak_mismatch_count}; errors: {ak_error_count}\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c19e25-72c1-4d62-b15f-6ba332049573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_breaking_points(key):\n",
    "    cluster_starts = [md.num_first_entry for md in events_rn.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "    print(\"Starts of clusters: \", cluster_starts)\n",
    "\n",
    "    step = 4\n",
    "    for cl_start in cluster_starts:\n",
    "        for i in range (cl_start-19, cl_start+19, step):\n",
    "            strt = i\n",
    "            end = i + step\n",
    "            arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "            arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "            \n",
    "            try:\n",
    "                 # Custom function to compare NaN-aware equality\n",
    "                def nan_equal(x, y):\n",
    "                    if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                        return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "                    return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "                # Check if the lengths of the outermost arrays are equal\n",
    "                assert len(arr_tt) == len(arr_rn)\n",
    "                \n",
    "                # Compare the arrays using the custom function\n",
    "                are_equal = nan_equal(arr_tt.tolist(), arr_rn.tolist())\n",
    "                assert(are_equal)\n",
    "                # print(\"EQUAL:\")\n",
    "                # print(f\"TT array: {ak.to_list(arr_tt)}\")\n",
    "                # print(f\"RN array: {ak.to_list(arr_rn)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"TT array: {arr_tt}\")\n",
    "                print(f\"RN array: {arr_rn}\")\n",
    "                print(\"Index: \", i, f\". Failure limits: {(strt, end)}\")\n",
    "                print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cb5c9e-e501-4e7b-8893-ad7fc0dc31df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_array_region(key, events_tt, events_rn):\n",
    "    cluster_starts = [md.num_first_entry for md in events_rn.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "    print(\"Starts of clusters: \", cluster_starts)\n",
    "    \n",
    "    strt = 44431\n",
    "    end = 44450\n",
    "\n",
    "    arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "    arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "\n",
    "    try:\n",
    "        # Custom function to compare NaN-aware equality\n",
    "        def nan_equal(x, y):\n",
    "            if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "            return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "        # Check if the lengths of the outermost arrays are equal\n",
    "        assert len(arr_tt) == len(arr_rn)\n",
    "        # Compare the arrays using the custom function\n",
    "        comparison_result = nan_equal(arr_tt.tolist(), arr_rn.tolist())\n",
    "        # Final assertion\n",
    "        assert comparison_result\n",
    "    except Exception as e:\n",
    "        print(f\"TT array: {arr_tt}\")\n",
    "        print(f\"RN array: {arr_rn}\")\n",
    "        print(f\"Failure limits: {(strt, end)}\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"TT:\", arr_tt)\n",
    "    print(\"RN:\", arr_rn)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2633d1c4-1a6e-40c9-b1c4-085cc62a6264",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to timeit on various functions: \n",
      "data_type                               func_name  time(s)\n",
      "       TT  load 10 arrays while using filter name   0.1041\n",
      "       RN  load 10 arrays while using filter name   0.0963\n",
      "       TT                         load all arrays  49.7793\n",
      "       RN                         load all arrays   4.5705\n",
      "       TT load all arrays while using filter name  52.8247\n",
      "       RN load all arrays while using filter name   4.5525\n",
      "       TT      load array while using filter name   0.0134\n",
      "       RN      load array while using filter name   0.0578\n",
      "       TT                load arrays for each key  21.0979\n",
      "       RN                load arrays for each key  55.0863\n",
      "       TT                               load file   0.3094\n",
      "       RN                               load file   0.0010\n"
     ]
    }
   ],
   "source": [
    "results = start_all_performance_tests()\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "\n",
    "# cluster_starts = [md.num_first_entry for md in events_632.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "# print(\"Starts of clusters: \", cluster_starts)\n",
    "\n",
    "# # # Must be sorted, because otherwise the order is different.\n",
    "# events_tt = events_list[0]\n",
    "# events_rn = events_list[1]\n",
    "# keys_tt = sorted(events_tt.keys(), key=str.lower)\n",
    "# keys_rn = sorted(events_rn._keys, key=str.lower)\n",
    "# # print(f\"TTree keys length: {len(keys_tt)}. RNTuple keys length: {len(keys_rn)}\")\n",
    "# compare_key_lists(keys_tt, keys_rn)\n",
    "\n",
    "# events_632 = events_list[0]\n",
    "# events_6x = events_list[1]\n",
    "# print(\"field records: \", events_6x.keys())\n",
    "# print(\"field records: \", events_632.keys())\n",
    "\n",
    "# key = \"SV_pAngle\"\n",
    "# strt = 1\n",
    "# end = 25\n",
    "# arr_632 = events_632.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "# arr_6x = events_6x.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "# print(\"Finished cell\")\n",
    "\n",
    "# key = \"Electron_hoe\"\n",
    "# collect_breaking_points(key)\n",
    "# print(\"Finished cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9ed82-8a6e-43f5-aaa7-8671910db521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
