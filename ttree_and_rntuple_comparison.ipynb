{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4baf183-a742-40e4-975a-03423411693e",
   "metadata": {},
   "source": [
    "### TTree and RNTuple loading comparison while using uproot\n",
    "\n",
    "Sources:\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:38.782002Z",
     "start_time": "2024-08-01T15:10:37.422997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.7\n",
      "uproot: 5.3.13.dev30+g0a84fd8\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2ef9b-15bc-468d-a477-50b8d5bf93ca",
   "metadata": {},
   "source": [
    "### File loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a00374a-83d5-48b8-8e68-7097936170ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:40.083914Z",
     "start_time": "2024-08-01T15:10:38.838844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = {}\n",
    "events_list = []\n",
    "\n",
    "## Remote files:\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/rntuple/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # RNTuple remote\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # TTree remote\n",
    "\n",
    "# Files downloaded locally:\n",
    "all_files[\"TT\"] = \"/home/cms-jovyan/my_root_files/ttree/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\" # TTree local\n",
    "all_files[\"RN\"] = \"/home/cms-jovyan/my_root_files/rntuple/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\"  # RNTuple local\n",
    "\n",
    "\n",
    "# all_files[\"632\"] = \"/home/cms-jovyan/my_root_files/rntuple_v6_632_0909.root\" # RNTuple, ROOT_632 (works)\n",
    "# all_files[\"6x\"] = \"/home/cms-jovyan/my_root_files/rntuple_v7_6_0909.root\" # RNTuple, ROOT_6_X (does not work)\n",
    "\n",
    "\n",
    "def load_files_with_uproot(files):\n",
    "    for fl in files.values():\n",
    "        with uproot.open(fl) as f:\n",
    "            events = f[\"Events\"]\n",
    "            events_list.append(events)\n",
    "            # print(\"File was loaded with uproot, event count: \", len(events.keys()))\n",
    "            \n",
    "            # NOTE: to access array: # events.arrays([\"Electron_pt\"])[\"Electron_pt\"]\n",
    "        \n",
    "def load_files_with_coffea(files):\n",
    "    for fl in files:\n",
    "        events = NanoEventsFactory.from_root({fl: \"Events\"}, schemaclass=NanoAODSchema).events()\n",
    "        events_list.append(events)\n",
    "        print(\"File was loaded with coffea, fields count: \", len(events.fields))\n",
    "        \n",
    "load_files_with_uproot(all_files)\n",
    "\n",
    "# load_files_with_coffea(all_files)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1800f9-82ab-44c2-9344-62a7ff6e617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Various available properties:\n",
    "# print(\"Name: \", events.name)\n",
    "# print(\"header: \", events.header)\n",
    "# print(\"footer: \", events.footer)\n",
    "# print(\"num_entries: \", events.num_entries)\n",
    "# print(\"len of field_names: \", len(events.field_names))\n",
    "# print(\"keys: \", len(events.keys()))\n",
    "# print(\" field_names: \", events.fields)\n",
    "# print(\"column_records: \", events.column_records[:10])\n",
    "# print(\"keys: \", events.keys()[:10])\n",
    "# print(\"_column_records_dict: \", events._column_records_dict)\n",
    "# print(\"_related_ids: \", events._related_ids)\n",
    "# print(\"page_list_envelopes: \", events.page_list_envelopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959fd9d-0c77-4cc5-b493-63eb613c2833",
   "metadata": {},
   "source": [
    "### timeit tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ee5919-2dcb-49f9-8065-2967a192620a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to timeit on various functions: \n",
      "data_type                          func_name  time(s)\n",
      "       TT load array while using filter name   0.0228\n",
      "       RN load array while using filter name   0.1986\n",
      "       TT                          load file   0.3074\n",
      "       RN                          load file   0.0004\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "events_dict = {}\n",
    "\n",
    "def format_test_results(times):\n",
    "    df = pd.DataFrame(times, columns =['data_type', 'func_name', 'time(s)'])\n",
    "    df = df.sort_values(by=['func_name'])\n",
    "    df['time(s)'] = df['time(s)'].round(4)\n",
    "    df['func_name'] = df['func_name'].str.replace('_', ' ', regex=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_file(data_type, file):\n",
    "    with uproot.open(file) as f:\n",
    "        events = f[\"Events\"]\n",
    "        events_dict[data_type] = events\n",
    "\n",
    "def load_arrays_for_each_key(events):\n",
    "    for key in events.keys():\n",
    "        events.arrays(filter_name=[key])[key]\n",
    "        \n",
    "def load_all_arrays(events):\n",
    "    events.arrays()\n",
    "    \n",
    "def load_all_arrays_while_using_filter_name(events):\n",
    "    chosen_keys = events.keys()\n",
    "    events.arrays(filter_name=chosen_keys)[chosen_keys]\n",
    "\n",
    "def load_array_while_using_filter_name(events):\n",
    "    key = \"nGenVisTau\"\n",
    "    events.arrays(filter_name=[key])[key]\n",
    "    \n",
    "    \n",
    "def load_24_arrays_while_using_filter_name(events):\n",
    "    chosen_keys = [\n",
    "        \"GenPart_pt\", \"GenPart_eta\", \"GenPart_phi\", \"CorrT1METJet_phi\",\n",
    "        \"GenJet_pt\", \"CorrT1METJet_eta\", \"SoftActivityJet_pt\",\n",
    "        \"Jet_eta\", \"Jet_phi\", \"SoftActivityJet_eta\", \"SoftActivityJet_phi\", \n",
    "        \"CorrT1METJet_rawPt\", \"Jet_btagDeepFlavB\", \"GenJet_eta\", \n",
    "        \"GenPart_mass\", \"GenJet_phi\",\n",
    "        \"Jet_puIdDisc\", \"CorrT1METJet_muonSubtrFactor\", \"Jet_btagDeepFlavCvL\",\n",
    "        \"Jet_btagDeepFlavQG\", \"Jet_mass\", \"Jet_pt\", \"GenPart_pdgId\",\n",
    "        \"Jet_btagDeepFlavCvB\", \"Jet_cRegCorr\"\n",
    "        ]\n",
    "    \n",
    "    events.arrays(filter_name=chosen_keys)[chosen_keys]\n",
    "        \n",
    "def start_all_performance_tests():\n",
    "    print(\"Starting to timeit on various functions: \")\n",
    "    times = []\n",
    "    \n",
    "    for data_type, file in all_files.items():\n",
    "        time_taken = timeit.timeit(lambda: load_file(data_type, file), number=1)\n",
    "        times.append((data_type, \"load_file\", time_taken))\n",
    "\n",
    "#         time_taken = timeit.timeit(lambda: load_arrays_for_each_key(events_dict[data_type]), number=1)\n",
    "#         times.append((data_type, \"load_arrays_for_each_key\", time_taken))\n",
    "        \n",
    "#         time_taken = timeit.timeit(lambda: load_all_arrays(events_dict[data_type]), number=1)\n",
    "#         times.append((data_type, \"load_all_arrays\", time_taken))\n",
    "        \n",
    "#         time_taken = timeit.timeit(lambda: load_all_arrays_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "#         times.append((data_type, \"load_all_arrays_while_using_filter_name\", time_taken))\n",
    "        \n",
    "#         time_taken = timeit.timeit(lambda: load_24_arrays_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "#         times.append((data_type, \"load_24_arrays_while_using_filter_name\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_array_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_array_while_using_filter_name\", time_taken))\n",
    "\n",
    "    \n",
    "    return format_test_results(times)\n",
    "\n",
    "\n",
    "results = start_all_performance_tests()\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235de38b-bd3a-4e7e-b29c-acd79ebc5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| func_name                          |     RN |     TT |\n",
      "|:-----------------------------------|-------:|-------:|\n",
      "| load array while using filter name | 0.1986 | 0.0228 |\n",
      "| load file                          | 0.0004 | 0.3074 |\n"
     ]
    }
   ],
   "source": [
    "# print(results.to_string(index=False))\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df_pivot = results.pivot(index='func_name', columns='data_type', values='time(s)')\n",
    "\n",
    "# Clean up the columns and reset index if needed\n",
    "df_pivot.columns.name = None  # Remove the name of the columns\n",
    "df_pivot = df_pivot.reset_index()  # Reset the index if you want a cleaner look\n",
    "\n",
    "# Output the pivoted DataFrame\n",
    "print(df_pivot.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58212611-abcb-42ed-96fc-9ad0a0e61d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GenPart_pt] ak arrays are equal\n",
      "[GenPart_eta] ak arrays are equal\n",
      "[GenPart_phi] ak comparison ERROR\n",
      "tt:  [[0, 0, 2.96, -0.182, 3.14, ..., 0.0825, 0.0348, 2.63, 2.68, 0.0828], ...] Type: 188600 * var * float32\n",
      "rn:  [[0, 0, 2.96, -0.182, 3.14, ..., 0.0825, 0.0348, 2.63, 2.68, 0.0828], ...] Type: 188600 * var * float32\n",
      "[CorrT1METJet_phi] ak arrays are equal\n",
      "[GenJet_pt] ak arrays are equal\n",
      "[CorrT1METJet_eta] ak arrays are equal\n",
      "[SoftActivityJet_pt] ak arrays are equal\n",
      "[Jet_eta] ak comparison ERROR\n",
      "tt:  [[-0.211, -0.984, 0.798, -1.5, -1.04, -2.27, -0.789], ..., [1.27, ..., 0.837]] Type: 188600 * var * float32\n",
      "rn:  [[-0.211, -0.984, 0.798, -1.5, -1.04, -2.27, -0.789], ..., [1.27, ..., 0.837]] Type: 188600 * var * float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell compares data between TTree and RNTuple for each key array, ensuring that RNTuple does not have corrupted data:\n",
    "def compare_all_arrays(events_1, events_2, keys):\n",
    "    ak_match_count = 0\n",
    "    ak_mismatch_count = 0\n",
    "    ak_error_count = 0\n",
    "        \n",
    "    for key in keys:\n",
    "        arrays_1 = events_1.arrays([key])[key]\n",
    "        arrays_2 = events_2.arrays([key])[key]\n",
    "\n",
    "        # Check if arrays are equal:\n",
    "        try:                \n",
    "            # Custom function to compare NaN-aware equality\n",
    "            def nan_equal(x, y):\n",
    "                if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                    return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "                return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "            # Check if the lengths of the outermost arrays are equal\n",
    "            assert len(arrays_1) == len(arrays_2)\n",
    "\n",
    "            # Compare the arrays using the custom function\n",
    "            are_equal = nan_equal(arrays_1.tolist(), arrays_2.tolist())\n",
    "\n",
    "            if are_equal:\n",
    "                ak_match_count += 1\n",
    "                print(f\"[{key}]\", \"ak arrays are equal\")\n",
    "            elif not are_equal:\n",
    "                ak_mismatch_count += 1\n",
    "                print(f\"[{key}]\", \"ak comparison MISMATCH\")\n",
    "                print(\"tt: \", arrays_1, f\"Type: {ak.type(arrays_1)}.\")\n",
    "                print(\"rn: \", arrays_2, f\"Type: {ak.type(arrays_2)}.\")\n",
    "\n",
    "        except:\n",
    "            ak_error_count += 1\n",
    "            print(f\"[{key}]\", \"ak comparison ERROR\")\n",
    "            print(\"tt: \", arrays_1, f\"Type: {ak.type(arrays_1)}\")\n",
    "            print(\"rn: \", arrays_2, f\"Type: {ak.type(arrays_2)}\")\n",
    "\n",
    "    print(f\"ak array comparison statistics: matched count: {ak_match_count}; mismatch count: {ak_mismatch_count}; errors: {ak_error_count}\")\n",
    "    \n",
    "events_tt = events_list[0]\n",
    "events_rn = events_list[1]\n",
    "\n",
    "keys = [\n",
    "        \"GenPart_pt\", \"GenPart_eta\", \"GenPart_phi\", \"CorrT1METJet_phi\",\n",
    "        \"GenJet_pt\", \"CorrT1METJet_eta\", \"SoftActivityJet_pt\",\n",
    "        \"Jet_eta\", \"Jet_phi\", \"SoftActivityJet_eta\", \"SoftActivityJet_phi\", \n",
    "        \"CorrT1METJet_rawPt\", \"Jet_btagDeepFlavB\", \"GenJet_eta\", \n",
    "        \"GenPart_mass\", \"GenJet_phi\",\n",
    "        \"Jet_puIdDisc\", \"CorrT1METJet_muonSubtrFactor\", \"Jet_btagDeepFlavCvL\",\n",
    "        \"Jet_btagDeepFlavQG\", \"Jet_mass\", \"Jet_pt\", \"GenPart_pdgId\",\n",
    "        \"Jet_btagDeepFlavCvB\", \"Jet_cRegCorr\"\n",
    "        ]\n",
    "\n",
    "compare_all_arrays(events_tt, events_rn, keys)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c19e25-72c1-4d62-b15f-6ba332049573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comparing only certain regions of arrays:\n",
    "def compare_array_region(key, events_tt, events_rn, strt, end):\n",
    "    arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "    arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "\n",
    "    try:\n",
    "        # Custom function to compare NaN-aware equality\n",
    "        def nan_equal(x, y):\n",
    "            if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "            return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "        # Check if the lengths of the outermost arrays are equal\n",
    "        assert len(arr_tt) == len(arr_rn)\n",
    "        # Compare the arrays using the custom function\n",
    "        comparison_result = nan_equal(arr_tt.tolist(), arr_rn.tolist())\n",
    "        # Final assertion\n",
    "        assert comparison_result\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"TT array: {arr_tt}\")\n",
    "        print(f\"RN array: {arr_rn}\")\n",
    "        print(f\"Failure limits: {(strt, end)}\")\n",
    "        print(\"\")\n",
    "        return False\n",
    "\n",
    "# Collect all regions near cluster edges, where data does not match:\n",
    "def collect_breaking_points(key):\n",
    "    cluster_starts = [md.num_first_entry for md in events_rn.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "    print(\"Starts of clusters: \", cluster_starts)\n",
    "\n",
    "    step = 4\n",
    "    for cl_start in cluster_starts:\n",
    "        for i in range (cl_start-9, cl_start+9, step):\n",
    "            strt = i\n",
    "            end = i + step\n",
    "            result = compare_array_region(key, events_tt, events_rn, strt, end)\n",
    "            print(f\"Range: ({strt},{end}). Match result: {result}\")\n",
    "\n",
    "key = \"Electron_hoe\"\n",
    "collect_breaking_points(key)\n",
    "print(\"Finished cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633d1c4-1a6e-40c9-b1c4-085cc62a6264",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_starts = [md.num_first_entry for md in events_632.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "print(\"Starts of clusters: \", cluster_starts)\n",
    "events_632 = events_list[0]\n",
    "events_6x = events_list[1]\n",
    "print(\"Keys: \", events_6x.keys())\n",
    "print(\"Keys: \", events_632.keys())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9ed82-8a6e-43f5-aaa7-8671910db521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
