{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4baf183-a742-40e4-975a-03423411693e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TTree and RNTuple loading comparison while using uproot\n",
    "\n",
    "RNTuple is a developed I/O subsystem available in ROOT as experimental feature. It supposed to fully change TTree. (https://indico.fnal.gov/event/23628/contributions/240607/attachments/154861/201536/rntuple-rootws22.pdf) <br> \n",
    "After RNTuple files are created with ROOT, we need to make sure that uproot is able to load data from them with no issues. <br>\n",
    "Additionally, checks must be done to compare TTree and RNTuple performance - it is expected that RNTuple should more efficient in the context of time and memory.<br>\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Various time comparison tests for TTree and RNTuple on uproot abstraction level;\n",
    "- Some data integrity tests for RNTuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:38.782002Z",
     "start_time": "2024-08-01T15:10:37.422997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.7\n",
      "uproot: 5.3.13.dev30+g0a84fd8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2ef9b-15bc-468d-a477-50b8d5bf93ca",
   "metadata": {},
   "source": [
    "### File loading\n",
    "Load ROOT files with one of two approaches: uproot or coffea.<br>\n",
    "NOTE: coffea uses Dask, which does not support RNTuple yet. Therefore, in this notebook we will only use data loaded with uproot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a00374a-83d5-48b8-8e68-7097936170ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T15:10:40.083914Z",
     "start_time": "2024-08-01T15:10:38.838844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was loaded with uproot, event count:  947\n",
      "File was loaded with uproot, event count:  947\n"
     ]
    }
   ],
   "source": [
    "all_files = {}\n",
    "events_dict = {}\n",
    "\n",
    "## Remote files:\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/rntuple/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # RNTuple remote\n",
    "# all_files.append(\"root://eospublic.cern.ch//eos/root-eos/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-amcatnlo-pythia8/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\") # TTree remote\n",
    "\n",
    "# Files downloaded locally:\n",
    "all_files[\"TT\"] = \"/home/cms-jovyan/my_root_files/ttree/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\" # TTree local\n",
    "all_files[\"RN\"] = \"/home/cms-jovyan/my_root_files/rntuple/cmsopendata2015_ttbar_19978_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext1-v1_60000_0004.root\"  # RNTuple local\n",
    "\n",
    "\n",
    "#\n",
    "# all_files[\"632\"] = \"/home/cms-jovyan/my_root_files/rntuple_v6_632_0909.root\" # RNTuple, ROOT_632 (works)\n",
    "# all_files[\"6x\"] = \"/home/cms-jovyan/my_root_files/rntuple_v7_6_0909.root\" # RNTuple, ROOT_6_X (does not work)\n",
    "\n",
    "\n",
    "def load_files_with_uproot(files):\n",
    "    for key, file in files.items():\n",
    "        with uproot.open(file) as f:\n",
    "            events = f[\"Events\"]\n",
    "            events_dict[key] = events\n",
    "            print(\"File was loaded with uproot, event count: \", len(events.keys()))\n",
    "            \n",
    "        \n",
    "def load_files_with_coffea(files):\n",
    "    for key, file in files.items():\n",
    "        events = NanoEventsFactory.from_root({file: \"Events\"}, schemaclass=NanoAODSchema).events()\n",
    "        events_dict[key] = events\n",
    "        print(\"File was loaded with coffea, fields count: \", len(events.fields))\n",
    "        \n",
    "load_files_with_uproot(all_files)\n",
    "\n",
    "# load_files_with_coffea(all_files)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1800f9-82ab-44c2-9344-62a7ff6e617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Various available properties:\n",
    "# print(\"Name: \", events.name)\n",
    "# print(\"header: \", events.header)\n",
    "# print(\"footer: \", events.footer)\n",
    "# print(\"num_entries: \", events.num_entries)\n",
    "# print(\"len of field_names: \", len(events.field_names))\n",
    "# print(\"keys: \", len(events.keys()))\n",
    "# print(\" field_names: \", events.fields)\n",
    "# print(\"column_records: \", events.column_records[:10])\n",
    "# print(\"keys: \", events.keys()[:10])\n",
    "# print(\"_column_records_dict: \", events._column_records_dict)\n",
    "# print(\"_related_ids: \", events._related_ids)\n",
    "# print(\"page_list_envelopes: \", events.page_list_envelopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959fd9d-0c77-4cc5-b493-63eb613c2833",
   "metadata": {},
   "source": [
    "### timeit tests\n",
    "Measure time for different operations related to data loading. Compare durations between TTree and RNTuple operations.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ee5919-2dcb-49f9-8065-2967a192620a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to timeit on various functions: \n",
      "timeit results (in seconds): \n",
      " | func_name                               |      RN |      TT |\n",
      "|:----------------------------------------|--------:|--------:|\n",
      "| load 24 arrays while using filter name  |  0.918  |  1.7113 |\n",
      "| load all arrays                         |  4.6872 | 45.8066 |\n",
      "| load all arrays while using filter name |  4.6342 | 50.521  |\n",
      "| load array while using filter name      |  0.1612 |  0.2453 |\n",
      "| load arrays for each key                | 54.9292 | 22.6699 |\n",
      "| load file                               |  0.0008 |  0.3058 |\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "events_dict = {}\n",
    "\n",
    "def format_test_results(times):\n",
    "    df = pd.DataFrame(times, columns =['data_type', 'func_name', 'time(s)'])\n",
    "    df = df.sort_values(by=['func_name'])\n",
    "    df['time(s)'] = df['time(s)'].round(4)\n",
    "    df['func_name'] = df['func_name'].str.replace('_', ' ', regex=False)\n",
    "    \n",
    "    # Pivot the DataFrame\n",
    "    df_pivot = df.pivot(index='func_name', columns='data_type', values='time(s)')\n",
    "\n",
    "    # Clean up the columns and reset index if needed\n",
    "    df_pivot.columns.name = None  # Remove the name of the columns\n",
    "    df_pivot = df_pivot.reset_index()  # Reset the index if you want a cleaner look\n",
    "\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "def load_file(data_type, file):\n",
    "    with uproot.open(file) as f:\n",
    "        events = f[\"Events\"]\n",
    "        events_dict[data_type] = events\n",
    "\n",
    "def load_arrays_for_each_key(events):\n",
    "    for key in events.keys():\n",
    "        events.arrays(filter_name=[key])[key]\n",
    "        \n",
    "def load_all_arrays(events):\n",
    "    events.arrays()\n",
    "    \n",
    "def load_all_arrays_while_using_filter_name(events):\n",
    "    chosen_keys = events.keys()\n",
    "    events.arrays(filter_name=chosen_keys)[chosen_keys]\n",
    "\n",
    "def load_array_while_using_filter_name(events):\n",
    "    key = \"GenPart_pt\"\n",
    "    events.arrays(filter_name=[key])[key]\n",
    "    \n",
    "    \n",
    "def load_24_arrays_while_using_filter_name(events):\n",
    "    chosen_keys = [\n",
    "        \"GenPart_pt\", \"GenPart_eta\", \"GenPart_phi\", \"CorrT1METJet_phi\",\n",
    "        \"GenJet_pt\", \"CorrT1METJet_eta\", \"SoftActivityJet_pt\",\n",
    "        \"Jet_eta\", \"Jet_phi\", \"SoftActivityJet_eta\", \"SoftActivityJet_phi\", \n",
    "        \"CorrT1METJet_rawPt\", \"Jet_btagDeepFlavB\", \"GenJet_eta\", \n",
    "        \"GenPart_mass\", \"GenJet_phi\",\n",
    "        \"Jet_puIdDisc\", \"CorrT1METJet_muonSubtrFactor\", \"Jet_btagDeepFlavCvL\",\n",
    "        \"Jet_btagDeepFlavQG\", \"Jet_mass\", \"Jet_pt\", \"GenPart_pdgId\",\n",
    "        \"Jet_btagDeepFlavCvB\", \"Jet_cRegCorr\"\n",
    "        ]\n",
    "    \n",
    "    events.arrays(filter_name=chosen_keys)[chosen_keys]\n",
    "        \n",
    "def start_all_performance_tests():\n",
    "    print(\"Starting to timeit on various functions: \")\n",
    "    times = []\n",
    "    \n",
    "    for data_type, file in all_files.items():\n",
    "        time_taken = timeit.timeit(lambda: load_file(data_type, file), number=1)\n",
    "        times.append((data_type, \"load_file\", time_taken))\n",
    "\n",
    "        time_taken = timeit.timeit(lambda: load_arrays_for_each_key(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_arrays_for_each_key\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_all_arrays(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_all_arrays\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_all_arrays_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_all_arrays_while_using_filter_name\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_24_arrays_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_24_arrays_while_using_filter_name\", time_taken))\n",
    "        \n",
    "        time_taken = timeit.timeit(lambda: load_array_while_using_filter_name(events_dict[data_type]), number=1)\n",
    "        times.append((data_type, \"load_array_while_using_filter_name\", time_taken))\n",
    "\n",
    "    \n",
    "    return format_test_results(times)\n",
    "\n",
    "\n",
    "results = start_all_performance_tests()\n",
    "# Output results:\n",
    "print(\"timeit results (in seconds): \\n\", results.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0830b7e-2a7e-4798-bb3d-54d0dcc801d5",
   "metadata": {},
   "source": [
    "### Check RNTuple data integrity\n",
    "When loading RNTuple data we need to be sure that data is correct. We do that by comparing RNTuple array data with TTree - it should be identical. <br>\n",
    "Comparison should be done with all arrays, but for demonstration purposes and time saving we use specific columns from https://github.com/iris-hep/idap-200gbps/blob/main/materialize_branches.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58212611-abcb-42ed-96fc-9ad0a0e61d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GenPart_pt] ak arrays are equal\n",
      "[GenPart_eta] ak arrays are equal\n",
      "[GenPart_phi] ak arrays are equal\n",
      "[CorrT1METJet_phi] ak arrays are equal\n",
      "[GenJet_pt] ak arrays are equal\n",
      "[CorrT1METJet_eta] ak arrays are equal\n",
      "[SoftActivityJet_pt] ak arrays are equal\n",
      "[Jet_eta] ak arrays are equal\n",
      "[Jet_phi] ak arrays are equal\n",
      "[SoftActivityJet_eta] ak arrays are equal\n",
      "[SoftActivityJet_phi] ak arrays are equal\n",
      "[CorrT1METJet_rawPt] ak arrays are equal\n",
      "[Jet_btagDeepFlavB] ak arrays are equal\n",
      "[GenJet_eta] ak arrays are equal\n",
      "[GenPart_mass] ak arrays are equal\n",
      "[GenJet_phi] ak arrays are equal\n",
      "[Jet_puIdDisc] ak arrays are equal\n",
      "[CorrT1METJet_muonSubtrFactor] ak arrays are equal\n",
      "[Jet_btagDeepFlavCvL] ak arrays are equal\n",
      "[Jet_btagDeepFlavQG] ak arrays are equal\n",
      "[Jet_mass] ak arrays are equal\n",
      "[Jet_pt] ak arrays are equal\n",
      "[GenPart_pdgId] ak arrays are equal\n",
      "[Jet_btagDeepFlavCvB] ak arrays are equal\n",
      "[Jet_cRegCorr] ak arrays are equal\n",
      "ak array comparison statistics: matched count: 25; mismatch count: 0; errors: 0\n"
     ]
    }
   ],
   "source": [
    "# This cell compares data between TTree and RNTuple for each key array, ensuring that RNTuple does not have corrupted data:\n",
    "def compare_all_arrays(events_1, events_2, keys):\n",
    "    ak_match_count = 0\n",
    "    ak_mismatch_count = 0\n",
    "    ak_error_count = 0\n",
    "        \n",
    "    for key in keys:\n",
    "        arrays_1 = events_1.arrays([key])[key]\n",
    "        arrays_2 = events_2.arrays([key])[key]\n",
    "\n",
    "        # Check if arrays are equal:\n",
    "        try:                \n",
    "            # Custom function to compare NaN-aware equality\n",
    "            def nan_equal(x, y):\n",
    "                if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                    return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "                return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "            # Check if the lengths of the outermost arrays are equal\n",
    "            assert len(arrays_1) == len(arrays_2)\n",
    "\n",
    "            # Compare the arrays using the custom function\n",
    "            are_equal = nan_equal(arrays_1.tolist(), arrays_2.tolist())\n",
    "\n",
    "            if are_equal:\n",
    "                ak_match_count += 1\n",
    "                print(f\"[{key}]\", \"ak arrays are equal\")\n",
    "            elif not are_equal:\n",
    "                ak_mismatch_count += 1\n",
    "                print(f\"[{key}]\", \"ak comparison MISMATCH\")\n",
    "                print(\"tt: \", arrays_1, f\"Type: {ak.type(arrays_1)}.\")\n",
    "                print(\"rn: \", arrays_2, f\"Type: {ak.type(arrays_2)}.\")\n",
    "\n",
    "        except:\n",
    "            ak_error_count += 1\n",
    "            print(f\"[{key}]\", \"ak comparison ERROR\")\n",
    "            print(\"tt: \", arrays_1, f\"Type: {ak.type(arrays_1)}\")\n",
    "            print(\"rn: \", arrays_2, f\"Type: {ak.type(arrays_2)}\")\n",
    "\n",
    "    print(f\"ak array comparison statistics: matched count: {ak_match_count}; mismatch count: {ak_mismatch_count}; errors: {ak_error_count}\")\n",
    "    \n",
    "events_tt = events_dict[\"TT\"]\n",
    "events_rn = events_dict[\"RN\"]\n",
    "\n",
    "keys = [\n",
    "        \"GenPart_pt\", \"GenPart_eta\", \"GenPart_phi\", \"CorrT1METJet_phi\",\n",
    "        \"GenJet_pt\", \"CorrT1METJet_eta\", \"SoftActivityJet_pt\",\n",
    "        \"Jet_eta\", \"Jet_phi\", \"SoftActivityJet_eta\", \"SoftActivityJet_phi\", \n",
    "        \"CorrT1METJet_rawPt\", \"Jet_btagDeepFlavB\", \"GenJet_eta\", \n",
    "        \"GenPart_mass\", \"GenJet_phi\",\n",
    "        \"Jet_puIdDisc\", \"CorrT1METJet_muonSubtrFactor\", \"Jet_btagDeepFlavCvL\",\n",
    "        \"Jet_btagDeepFlavQG\", \"Jet_mass\", \"Jet_pt\", \"GenPart_pdgId\",\n",
    "        \"Jet_btagDeepFlavCvB\", \"Jet_cRegCorr\"\n",
    "        ]\n",
    "\n",
    "compare_all_arrays(events_tt, events_rn, keys)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98694daf-ebb1-4b15-9527-7ec770c4b1ee",
   "metadata": {},
   "source": [
    "### Test RNTuple data loading from cluster edges\n",
    "There was an issue detected, where RNTuple array data integrity was lost each time when index range crossed edge boundaries. (PR: https://github.com/scikit-hep/uproot5/pull/1285) This cell checks small set of data around clustary edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c19e25-72c1-4d62-b15f-6ba332049573",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts of clusters:  [17224, 51094, 85025, 118948, 152870, 186775]\n",
      "Range: (17215,17219). Match result: True\n",
      "Range: (17219,17223). Match result: True\n",
      "Range: (17223,17227). Match result: True\n",
      "Range: (17227,17231). Match result: True\n",
      "Range: (17231,17235). Match result: True\n",
      "Range: (51085,51089). Match result: True\n",
      "Range: (51089,51093). Match result: True\n",
      "Range: (51093,51097). Match result: True\n",
      "Range: (51097,51101). Match result: True\n",
      "Range: (51101,51105). Match result: True\n",
      "Range: (85016,85020). Match result: True\n",
      "Range: (85020,85024). Match result: True\n",
      "Range: (85024,85028). Match result: True\n",
      "Range: (85028,85032). Match result: True\n",
      "Range: (85032,85036). Match result: True\n",
      "Range: (118939,118943). Match result: True\n",
      "Range: (118943,118947). Match result: True\n",
      "Range: (118947,118951). Match result: True\n",
      "Range: (118951,118955). Match result: True\n",
      "Range: (118955,118959). Match result: True\n",
      "Range: (152861,152865). Match result: True\n",
      "Range: (152865,152869). Match result: True\n",
      "Range: (152869,152873). Match result: True\n",
      "Range: (152873,152877). Match result: True\n",
      "Range: (152877,152881). Match result: True\n",
      "Range: (186766,186770). Match result: True\n",
      "Range: (186770,186774). Match result: True\n",
      "Range: (186774,186778). Match result: True\n",
      "Range: (186778,186782). Match result: True\n",
      "Range: (186782,186786). Match result: True\n",
      "Finished cell.\n"
     ]
    }
   ],
   "source": [
    "# Comparing only certain regions of arrays:\n",
    "def compare_array_region(key, events_tt, events_rn, strt, end):\n",
    "    arr_tt = events_tt.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "    arr_rn = events_rn.arrays(filter_name=[key], entry_start=strt, entry_stop=end)[key]\n",
    "\n",
    "    try:\n",
    "        # Custom function to compare NaN-aware equality\n",
    "        def nan_equal(x, y):\n",
    "            if isinstance(x, (list, ak.Array)) and isinstance(y, (list, ak.Array)):\n",
    "                return all(nan_equal(a, b) for a, b in zip(x, y))\n",
    "            return (x == y) or (np.isnan(x) and np.isnan(y))\n",
    "        # Check if the lengths of the outermost arrays are equal\n",
    "        assert len(arr_tt) == len(arr_rn)\n",
    "        # Compare the arrays using the custom function\n",
    "        comparison_result = nan_equal(arr_tt.tolist(), arr_rn.tolist())\n",
    "        # Final assertion\n",
    "        assert comparison_result\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"TT array: {arr_tt}\")\n",
    "        print(f\"RN array: {arr_rn}\")\n",
    "        print(f\"Failure limits: {(strt, end)}\")\n",
    "        print(\"\")\n",
    "        return False\n",
    "\n",
    "# Collect all regions near cluster edges, where data does not match:\n",
    "def collect_breaking_points(key):\n",
    "    cluster_starts = [md.num_first_entry for md in events_rn.cluster_summaries][1:] # Skip first, because it is 0.\n",
    "    print(\"Starts of clusters: \", cluster_starts)\n",
    "\n",
    "    step = 4\n",
    "    for cl_start in cluster_starts:\n",
    "        for i in range (cl_start-9, cl_start+9, step):\n",
    "            strt = i\n",
    "            end = i + step\n",
    "            result = compare_array_region(key, events_tt, events_rn, strt, end)\n",
    "            print(f\"Range: ({strt},{end}). Match result: {result}\")\n",
    "\n",
    "key = \"Electron_hoe\"\n",
    "collect_breaking_points(key)\n",
    "print(\"Finished cell.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
